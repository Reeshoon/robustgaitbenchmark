<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>RobustGait: Robustness Analysis for Appearance-Based Gait Recognition</title>

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

    <!-- External CSS -->
    <link rel="stylesheet" href="style.css">
</head>

<body>
<div class="container">

    <!-- Title -->
    <h1>RobustGait: Robustness Analysis for Appearance-Based Gait Recognition</h1>

    <!-- Authors -->
    <div class="authors">Reeshoon Sayera, Akash Kumar, Sirshapan Mitra, Prudvi Kamtam, Yogesh S Rawat</div>

    <!-- Affiliation -->
    <div class="affiliation">University of Central Florida</div>

    <!-- Conference -->
    <div class="conference">WACV 2026</div>

    <!-- Buttons -->
    <div class="button-row">
        <a class="button" href="" target="_blank">üìÑ Paper</a>
        <a class="button" href="https://arxiv.org/abs/2511.13065" target="_blank">üìù arXiv</a>
        <a class="button" href="https://github.com/Reeshoon/RobustGait" target="_blank">üíª Code</a>
        <a class="button" href="" target="_blank">üìÇ Data</a>
    </div>

    <!-- Pipeline Image -->
    <div class="img-center">
        <img src="images/pipeline.png" class="img-pipeline" alt="Pipeline Image">
    </div>

    <!-- Teaser Stack -->
    <div class="teaser-stack">
        <img src="images/teaser_left.png" class="teaser-img-small" alt="Left Block">
        <img src="images/teaser_middle.png" class="teaser-img-small" alt="Middle Block">
        <img src="images/teaser_right.png" class="teaser-img-large" alt="Right Block">
    </div>

    <div class="section-divider"></div>

    <!-- Abstract -->
    <h2>Abstract</h2>
    <p>
    Appearance-based gait recognition have achieved strong performance on controlled datasets, yet systematic evaluation of its robustness
    to real-world corruptions and silhouette variability remains lacking. We present RobustGait, a framework for fine-grained robustness
    evaluation of appearance-based gait recognition systems.
    RobustGait evaluation spans four dimensions: the type of perturbation (digital, environmental, temporal, occlusion), the silhouette
    extraction method (segmentation and parsing networks), the architectural capacities of gait recognition models, and various deployment scenarios.
    The benchmark introduces 15 corruption types at 5 severity levels across CASIA-B, CCPG, and SUSTech1K, with in-the-wild validation on MEVID,
    and evaluates six state-of-the-art gait systems.
    We came across several exciting insights. First, applying noise at the RGB level better reflects real-world degradation, and reveal how distortions
    propagate through silhouette extraction to the downstream gait recognition systems. Second, gait accuracy is highly sensitive to silhouette extractor biases,
    revealing an overlooked source of benchmark bias. Third, robustness is dependent on both the type of perturbation and the architectural design.
    Finally, we explore robustness-enhancing strategies, showing that noise-aware training and knowledge distillation improve performance and move toward
    deployment-ready systems.
    </p>

    <div class="section-divider"></div>

    <!-- Noise Overview -->
    <h2>Robustness Under Real-World Noise</h2>
    <p>
    RobustGait evaluates real-world degradations across digital, environmental, temporal, and occlusion-based noise.
    Digital noise and occlusions cause the strongest performance drops because they distort or remove key body structures needed for silhouette extraction.
    Environmental and temporal noise affect appearance and motion but generally preserve shape, leading to more moderate degradation.
    Overall, the benchmark reveals that gait models remain most vulnerable when structural integrity of the silhouette is compromised.
    </p>

    <div class="img-center">
        <img src="images/noise_overview.png" class="img-noise" alt="Noise Overview" loading="lazy">
    </div>

    <div class="section-divider"></div>

    <!-- Silhouette Extraction Bias -->
    <h2>Silhouette Extraction Bias</h2>
    <p>
    Different silhouette extractors produce vastly different silhouette quality. This leads to
    <b>unfair benchmark comparisons</b> and can alter Rank-1 accuracy by more than 20%.
    High-IoU extractors (SCHP, M2FP) preserve structure better and significantly boost gait model performance.
    </p>

    <div class="img-center">
        <img src="images/segmod.png" class="img-seg" alt="Segmentation Comparison" loading="lazy">
    </div>

    <div class="section-divider"></div>

    <!-- Robustness of Gait Models -->
    <h2>Robustness of Gait Models</h2>
    <p>
    Gait models are most robust to environmental and temporal noise, but struggle with digital distortions and occlusion.
    Transformers show the strongest overall robustness, while CNNs degrade most under local corruptions, and set-based models remain
    stable under temporal disruptions.
    Overall, robustness depends strongly on both the type of perturbation and the model architecture.
    </p>

    <div class="img-center">
        <img src="images/gait_models_robustness_analysis.png" class="img-robustness" alt="Noise Severity Performance" loading="lazy">
    </div>

    <div class="section-divider"></div>

    <!-- Deployment Scenarios -->
    <h2>Deployment Scenarios</h2>
    <p>
    Deployment scenarios reveal that gait models can struggle when training and testing conditions differ.
    When the gallery is noisy, performance drops sharply because both reference and query features become degraded, making matching difficult.
    Models are also highly sensitive to changes in silhouette extraction pipelines ‚Äî training on one extractor and testing on another
    leads to large accuracy drops.
    Finally, cross-dataset evaluation shows that the best-performing extractor depends on dataset characteristics,
    highlighting that both dataset structure and extraction method strongly influence real-world performance.
    </p>

    <div class="image-grid">
        <div class="image-row">
            <img src="images/cross_parser_casia.png" class="half-img" alt="Cross Parser" loading="lazy">
            <img src="images/absolute_noisy_vs_gallery_comparison.png" class="half-img" alt="Absolute Robustness" loading="lazy">
        </div>
        <div class="image-row">
            <img src="images/cross_dataset_bars.png" class="full-img" alt="Cross Dataset Bars" loading="lazy">
        </div>
    </div>

    <div class="section-divider"></div>

    <!-- Improving Robustness -->
    <!-- <h2>Improving Robustness</h2>
    <p>
        We propose two effective strategies:<br><br>

        <b>Noise-Aware Training:</b> Train with RGB-level noise, improves robustness but slightly reduces clean accuracy.<br><br>

        <b>Distillation with LoRA:</b> A clean-teacher guides a noisy-student, preserves clean accuracy while improving robustness.
    </p>

    <div class="section-divider"></div> -->

    <!-- Citation -->
    <h2>Citation</h2>
    <pre class="bibtex-box">
        @inproceedings{
            sayera2026robustgait,
            title={{ RobustGait: Robustness Analysis for Appearance-Based Gait Recognition }},
            author={Reeshoon Sayera and Akash Kumar and Sirshapan Mitra and Prudvi Kamtam and Yogesh S Rawat},
            booktitle={Winter Conference on Applications of Computer Vision (WACV)},
            year={2026},
            url={https://arxiv.org/abs/2511.13065}
        }
    </pre>

    <div class="footer">¬© 2025 RobustGait Authors ‚Äî MIT License</div>
</div>
</body>
</html>
