<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RobustGait: Robustness Analysis for Appearance-Based Gait Recognition</title>

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

    <!-- External CSS -->
    <link rel="stylesheet" href="style.css">
</head>

<body>

<div class="container">

    <!-- Title -->
    <h1>RobustGait: Robustness Analysis for Appearance-Based Gait Recognition</h1>

    <!-- Authors -->
    <div class="authors">
        Reeshoon Sayera,
        Akash Kumar,
        Sirshapan Mitra,
        Prudvi Kamtam,
        Yogesh S Rawat
    </div>

    <!-- Affiliation -->
    <div class="affiliation"> University of Central Florida</div>

    <!-- Conference -->
    <div class="conference">WACV 2026</div>

    <!-- Buttons -->
    <div class="button-row">
        <a class="button" href="" target="_blank">üìÑ Paper</a>
        <a class="button" href="https://arxiv.org/abs/2511.13065" target="_blank">üìù arXiv</a>
        <a class="button" href="https://github.com/Reeshoon/RobustGait" target="_blank">üíª Code</a>
    </div>
    
    <div class="img-wrapper">
        <img src="images/pipeline.png" class="img-pipeline" alt="Pipeline Image">
    </div>

    <div class="img-wrapper">
        <img src="images/teaser.drawio.png" class="img-teaser" alt="Teaser Image">
    </div>

     <!-- Abstract -->
     <h2>Abstract</h2>
     <p>
         Appearance-based gait recognition have achieved strong performance on controlled datasets, yet systematic evaluation of its robustness to 
         real-world corruptions and silhouette variability remains lacking. We present RobustGait, a framework for fine-grained robustness evaluation 
         of appearance-based gait recognition systems. RobustGait evaluation spans four dimensions: the type of perturbation (digital, environmental, 
         temporal, occlusion), the silhouette extraction method (segmentation and parsing networks), the architectural capacities of gait recognition models, 
         and various deployment scenarios. The benchmark introduces 15 corruption types at 5 severity levels across CASIA-B, CCPG, and SUSTech1K, 
         with in-the-wild validation on MEVID, and evaluates six state-of-the-art gait systems. We came across several exciting insights. 
         First, applying noise at the RGB level better reflects real-world degradation, and reveal how distortions propagate through silhouette extraction to 
         the downstream gait recognition systems. Second, gait accuracy is highly sensitive to silhouette extractor biases, revealing an overlooked source of benchmark bias. 
         Third, robustness is dependent on both the type of perturbation and the architectural design. Finally, we explore robustness-enhancing strategies, showing that noise-aware
          training and knowledge distillation improve performance and move toward deployment-ready systems.
     </p>
    

    <div class="section-divider"></div>
    
    <h2>Noise Types & Impact</h2>

    <div class="img-wrapper">
        <img src="images/noise_overview.png" class="img-noise" alt="Noise Overview">
    </div>
    <p>
        RobustGait evaluates real-world degradations across digital, environmental, temporal, and occlusion-based noise. 
        Digital noise and occlusions cause the strongest performance drops because they distort or remove key body structures needed for silhouette extraction. 
        Environmental and temporal noise affect appearance and motion but generally preserve shape, leading to more moderate degradation. 
        Overall, the benchmark reveals that gait models remain most vulnerable when structural integrity of the silhouette is compromised.
    </p>

    <div class="section-divider"></div>

    <h2>Silhouette Extraction Bias</h2>
    <p>
        Different silhouette extractors produce vastly different silhouette quality. This leads to <b>unfair benchmark comparisons</b>
        and can alter Rank-1 accuracy by more than 20%. High-IoU extractors (SCHP, M2FP) preserve structure better
        and significantly boost gait model performance.
    </p>

    <div class="img-wrapper">
        <img src="images/seg_extractors.png" class="img-segmod" alt="Segmentation Comparison">
    </div>

    <div class="section-divider"></div>

    <h2>Robustness of Gait Models</h2>
    <p>
        Our analysis shows that gait models are:
        <br><br>
        ‚Ä¢ <b>Most robust</b> to environmental and temporal noise  
        ‚Ä¢ <b>Most vulnerable</b> to digital noise and occlusion  
        <br>
        CNN models fail under local corruptions, while transformer architectures (e.g., SwinGait) maintain stable performance.
    </p>

    <div class="img-wrapper">
        <img src="images/noise_severity.png" class="img-noise" alt="Noise Severity Performance">
    </div>

    <div class="section-divider"></div>

    <h2>Improving Robustness</h2>
    <p>
        We propose two effective strategies:
        <br><br>
        ‚úî <b>Noise-Aware Training:</b> Train with RGB-level noise ‚Üí improves robustness but slightly reduces clean accuracy.<br>
        ‚úî <b>Distillation with LoRA:</b> A clean-teacher guides a noisy-student ‚Üí preserves clean accuracy while improving robustness.
    </p>

    <div class="img-wrapper">
        <img src="images/distillation.png" class="img-segmod" alt="Distillation Diagram">
    </div>

    <div class="section-divider"></div>

    <!-- Citation -->
    <h2>Citation</h2>
    <pre style="background:#eee; padding:20px; text-align:left; max-width:800px; margin:0 auto; border-radius:8px;">
@inproceedings{sayera2026robustgait,
  title={RobustGait: Robustness Analysis for Appearance-Based Gait Recognition},
  author={Sayera, Reeshoon and Kumar, A and Mitra, S and Kamtam, P},
  booktitle={WACV},
  year={2026}
}
    </pre>

    <div class="footer">
        ¬© 2025 RobustGait Authors ‚Äî MIT License
    </div>

</div>

</body>
</html>
